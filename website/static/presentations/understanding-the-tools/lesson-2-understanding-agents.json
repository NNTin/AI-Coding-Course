{
  "metadata": {
    "title": "Understanding Agents",
    "lessonId": "lesson-2-understanding-agents",
    "estimatedDuration": "35-45 minutes",
    "learningObjectives": [
      "Master agent execution loops",
      "Understand context as text",
      "Leverage stateless LLM advantage",
      "Engineer context to steer"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Understanding Agents",
      "subtitle": "How LLMs and agent frameworks work together",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "This lesson explains how agents combine LLM reasoning with autonomous execution. We'll demystify the agent loop, reveal that everything is just text in a context window, and show how to engineer context to steer agent behavior.",
        "timing": "1 minute",
        "discussion": "Ask who has used chat interfaces vs CLI agents - we'll see why CLI agents win for implementation work.",
        "context": "Building on Lesson 1's brain/body metaphor, we now explore the mechanics of how these systems operate autonomously.",
        "transition": "Let's start by understanding the core execution loop that powers all coding agents."
      }
    },
    {
      "type": "concept",
      "title": "The Agent Execution Loop",
      "content": [
        "Perceive: Read context (files, state, history)",
        "Reason: LLM generates plan and next action",
        "Act: Execute tool (Read, Edit, Bash, etc.)",
        "Observe: Process tool output",
        "Verify: Goal achieved? If no, iterate"
      ],
      "speakerNotes": {
        "talkingPoints": "Agents aren't just LLMs responding to prompts - they're feedback loops combining reasoning with action. The cycle continues autonomously until the goal is met. This is fundamentally different from chat interfaces that require manual intervention at each step.",
        "timing": "3-4 minutes",
        "discussion": "Ask: What breaks when you remove any step from this loop? The answer reveals why agents can work autonomously while chat interfaces can't.",
        "context": "In production, this loop might iterate 10-50 times for complex tasks. Understanding it helps you debug when agents get stuck or drift off-task.",
        "transition": "Let's see this loop in action with a concrete example comparing chat vs agent workflows."
      }
    },
    {
      "type": "comparison",
      "title": "Chat Interface vs Agent Workflow",
      "left": {
        "label": "Chat Interface",
        "content": [
          "You ask how to add authentication",
          "LLM provides code suggestion",
          "You manually edit files",
          "You encounter error, ask again",
          "You manually fix based on response"
        ]
      },
      "right": {
        "label": "Agent Workflow",
        "content": [
          "You specify: add authentication",
          "Agent reads API files autonomously",
          "Agent edits files, runs tests",
          "Tests fail, agent analyzes error",
          "Agent fixes code, verifies tests pass"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "The key difference is the agent closes the loop automatically. Chat requires you to be the execution layer, manually running commands and copying results back. Agents automate that entire cycle, iterating until the goal is achieved.",
        "timing": "3-4 minutes",
        "discussion": "Ask the class: How many round-trips does it typically take in a chat interface to complete a feature? Compare that to a single agent invocation.",
        "context": "In production, chat workflows take 5-10 manual iterations for tasks agents complete in one autonomous session. This isn't just convenience - it's a qualitative difference in how you work.",
        "transition": "Now let's reveal what's actually happening under the hood - it's simpler than you might think."
      }
    },
    {
      "type": "concept",
      "title": "Under the Hood: It's All Just Text",
      "content": [
        "Everything flows through a single context window",
        "System prompts, user input, tool calls, results - all text",
        "Agent reasoning isn't separate - it's visible text generation",
        "No magic, no hidden state, no separate reasoning engine"
      ],
      "speakerNotes": {
        "talkingPoints": "This is the fundamental truth that demystifies agents. Every interaction is a text conversation in one large buffer. When you see agent reasoning, that's not internal thought - it's text being generated in the context. Understanding this textual nature helps you anticipate behavior, debug confusion, and structure better prompts.",
        "timing": "2-3 minutes",
        "discussion": "Note: Extended thinking modes (Anthropic, OpenAI) complicate this - you see a summary but the full reasoning is hidden and opaque. You're billed for hidden tokens but can't debug them.",
        "context": "This is why context window size matters. If the agent forgets something, it probably scrolled out of the visible context.",
        "transition": "Let's look at exactly what this text stream looks like in practice."
      }
    },
    {
      "type": "codeExecution",
      "title": "Concrete Example: Context as Text",
      "steps": [
        {
          "line": "SYSTEM: You are Claude Code. You have access to: Read, Edit, Bash, Grep...",
          "highlightType": "human",
          "annotation": "System instructions establish agent behavior and available tools"
        },
        {
          "line": "USER: Add email validation to the registration endpoint",
          "highlightType": "human",
          "annotation": "User task enters the context as text"
        },
        {
          "line": "ASSISTANT: I'll search for the registration endpoint first.",
          "highlightType": "prediction",
          "annotation": "LLM predicts next action based on context"
        },
        {
          "line": "Tool: Grep(pattern=\"register\", path=\"**/*.ts\")",
          "highlightType": "execution",
          "annotation": "Agent executes search tool"
        },
        {
          "line": "TOOL_RESULT: Found in src/routes/auth.ts:12, src/handlers/user.ts:45",
          "highlightType": "feedback",
          "annotation": "Search results added to context as text"
        },
        {
          "line": "ASSISTANT: Let me read the handler to see current validation.",
          "highlightType": "prediction",
          "annotation": "LLM decides next step with new information"
        },
        {
          "line": "Tool: Read(\"src/handlers/user.ts\")",
          "highlightType": "execution",
          "annotation": "Agent reads file content"
        },
        {
          "line": "TOOL_RESULT: [file contents showing no email validation]",
          "highlightType": "feedback",
          "annotation": "File contents become part of context"
        },
        {
          "line": "ASSISTANT: I'll add email validation using Zod schema.",
          "highlightType": "prediction",
          "annotation": "LLM plans implementation based on current state"
        },
        {
          "line": "Tool: Edit(file, old_string, new_string) with Zod validation",
          "highlightType": "execution",
          "annotation": "Agent modifies code"
        },
        {
          "line": "TOOL_RESULT: Edit successful",
          "highlightType": "feedback",
          "annotation": "Success confirmation added to context"
        },
        {
          "line": "Task complete: Email validation added and verified with tests",
          "highlightType": "summary",
          "annotation": "Agent concludes based on full conversation history"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "This entire conversation exists as one continuous text stream in the LLM's context window. System instructions, your task, tool calls, results, and responses - all text flowing through sequentially. The agent only knows what's in this text buffer.",
        "timing": "4-5 minutes",
        "discussion": "Ask students: What happens if this conversation gets too long? What would the agent forget first? This reveals context window limitations.",
        "context": "Understanding this flow helps you debug when agents make mistakes. If the agent forgets something you mentioned earlier, it likely scrolled out of the context window.",
        "transition": "Now here's the game-changer: the LLM is completely stateless, and that's actually a massive advantage."
      }
    },
    {
      "type": "concept",
      "title": "The Stateless Advantage",
      "content": [
        "LLM has no memory beyond current context",
        "Previous responses exist as text, not memories",
        "Clean-slate exploration: no bias from earlier decisions",
        "Unbiased review: agent can audit its own code objectively",
        "Fresh context = fresh perspective"
      ],
      "speakerNotes": {
        "talkingPoints": "The LLM being stateless is a feature, not a bug. Start a new conversation, and the agent has zero bias from previous decisions. This enables powerful workflows: implement JWT in one context, sessions in another - each gets evaluated on merit. Or have the agent write code then objectively review it in a fresh context without defensive bias.",
        "timing": "3-4 minutes",
        "discussion": "Ask: How would this change if the LLM remembered everything from past conversations? Would that be better or worse? Most realize memory creates bias and compounds errors.",
        "context": "In production, this enables Generate → Review → Iterate workflows where the agent writes code then audits it with full scrutiny, or multi-perspective analysis (security in one context, performance in another).",
        "transition": "Let's visualize how clean context prevents the agent from defending poor decisions."
      }
    },
    {
      "type": "visual",
      "title": "Context and Agent Behavior",
      "component": "AbstractShapesVisualization",
      "caption": "Clean context prevents agent hallucinations",
      "speakerNotes": {
        "talkingPoints": "Same code, different contexts, completely different evaluations. In one context with authorship revealed: 'looks sound overall'. In a fresh context without bias: 'Critical security vulnerabilities - localStorage exposes tokens to XSS attacks'. This isn't inconsistency, it's the stateless advantage enabling objective analysis.",
        "timing": "2-3 minutes",
        "discussion": "Ask students to share examples where they've seen agents defend bad code. How would a fresh context have changed the outcome?",
        "context": "This is why multi-agent workflows are powerful - use different contexts for different perspectives without one agent defending its previous decisions.",
        "transition": "So how do you control what's in the context? Through tools - the mechanisms agents use to interact with the world."
      }
    },
    {
      "type": "concept",
      "title": "Tools: Built-In vs External",
      "content": [
        "Built-in: Read, Edit, Bash, Grep, Write, Glob",
        "Optimized for LLM workflows (edge cases, output format, safety)",
        "External: MCP protocol for custom integrations",
        "Connect to databases, APIs, cloud platforms",
        "Agent discovers tools at runtime"
      ],
      "speakerNotes": {
        "talkingPoints": "Tools are how agents interact with the world and control context. Built-in tools aren't just shell command wrappers - they're engineered with LLM-friendly output formats, edge case handling, and safety guardrails. MCP (Model Context Protocol) extends this with standardized plugins for databases, APIs, and cloud platforms.",
        "timing": "3 minutes",
        "discussion": "Ask: What tools would you add for your production environment? Common answers: database clients, deployment systems, monitoring integrations.",
        "context": "In production, you'll use built-in tools 90% of the time. MCP becomes critical when you need domain-specific integrations (Stripe for payments, AWS for infrastructure).",
        "transition": "Now let's understand why CLI agents deliver superior developer experience compared to chat or IDE agents."
      }
    },
    {
      "type": "comparison",
      "title": "Chat/IDE Agents vs CLI Agents",
      "left": {
        "label": "Chat/IDE Agents",
        "content": [
          "Tightly coupled to single window/project",
          "Context resets with each conversation",
          "Blocked until agent completes or you cancel",
          "Manual copy-paste for code execution"
        ]
      },
      "right": {
        "label": "CLI Agents",
        "content": [
          "Multiple terminals = concurrent projects",
          "Independent contexts per tab",
          "Context-switch freely while agents work",
          "Automatic execution and iteration"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Chat interfaces excel at questions and brainstorming, but CLI agents win for implementation. The concurrent work advantage is huge: open three tabs, run agents on different projects simultaneously. IDE agents like Cursor or Copilot block your entire workspace until completion. CLI unlocks parallelism without managing conversation threads.",
        "timing": "3-4 minutes",
        "discussion": "Ask: How many projects do you actively work on? How often do you context-switch? CLI agents let you keep multiple agents working while you focus elsewhere.",
        "context": "In production, senior engineers juggle multiple tasks - refactoring in one repo, debugging in another, reviewing in a third. CLI agents enable this naturally.",
        "transition": "We'll explore concurrent workflows deeply in Lesson 7. For now, let's tie everything together."
      }
    },
    {
      "type": "concept",
      "title": "Context Engineering and Steering",
      "content": [
        "Context window is the agent's entire world",
        "You control behavior by engineering context",
        "Vague context → wandering behavior",
        "Precise, scoped context → focused execution",
        "Steer upfront with prompts or mid-conversation when drifting"
      ],
      "speakerNotes": {
        "talkingPoints": "Effective AI-assisted coding is about engineering context to steer behavior. Everything the agent knows comes from text in the context: system prompts, your instructions, tool results, conversation history. This is system design thinking applied to text. You're already good at designing interfaces and contracts - now apply those skills to engineer context.",
        "timing": "3-4 minutes",
        "discussion": "Ask: What happens if you give the agent access to an entire 50-file codebase at once? Answer: It gets overwhelmed or focuses on the wrong parts. Scoped context is critical.",
        "context": "The rest of this course teaches how to apply system design thinking to context engineering across real coding scenarios.",
        "transition": "Let's wrap up with the key takeaways from this lesson."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "Agents loop autonomously until completion",
        "Everything is text in context",
        "Stateless LLMs enable objective review",
        "CLI agents unlock concurrent work",
        "Engineer context to steer behavior"
      ],
      "speakerNotes": {
        "talkingPoints": "Remember: agents close the execution loop automatically, everything flows as text through context, stateless behavior is an advantage not a limitation, CLI agents let you work on multiple projects concurrently, and your job is to engineer context that steers behavior precisely. Master these concepts and you'll understand how to leverage agents effectively in production.",
        "timing": "2 minutes",
        "discussion": "Final question: How would you use stateless contexts to review your own code more objectively? This previews the multi-agent workflows we'll cover in Lesson 7.",
        "context": "These fundamentals apply regardless of which agent framework or LLM provider you use. They're the invariants of AI-assisted coding.",
        "transition": "Next lesson: High-Level Methodology - how to structure your workflow when working with agents."
      }
    }
  ]
}
