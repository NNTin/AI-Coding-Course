{
  "metadata": {
    "title": "Lesson 7: Planning & Execution",
    "lessonId": "lesson-7-planning-execution",
    "estimatedDuration": "35-40 minutes",
    "learningObjectives": [
      "Ground agents in actual codebase patterns",
      "Review agent plans before autonomous execution",
      "Set up parallel workflows with git worktrees",
      "Validate reasoning, not just generated code"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Planning & Execution",
      "subtitle": "From code generators to reliable code-producing machines",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "This lesson shifts focus from gathering context (Lesson 5) to actively using context during planning and execution. We're moving beyond one-time upfront grounding to continuous context management. The key insight: agents are code generators by default. Our job is to guide them toward reliable execution through deliberate planning review, strategic questioning, and parallel workflows.",
        "timing": "1 minute",
        "discussion": "How many of you have had an agent generate code that compiled but didn't match your actual codebase patterns?",
        "context": "Lesson 5 covered grounding through RAG and semantic search. Now we focus on execution tactics that turn agents into reliable tools.",
        "transition": "Let's start with the first tactical technique: active context engineering."
      }
    },
    {
      "type": "concept",
      "title": "Active Context Engineering",
      "content": [
        "Show agents patterns from YOUR codebase, not generic docs",
        "Questions are context engineering tools—they load the window",
        "Require evidence to force grounding, not guessing",
        "Challenge logic with clarifying questions"
      ],
      "speakerNotes": {
        "talkingPoints": "Context engineering is deliberate. Every interaction either loads relevant information into the context window or lets the agent guess from training data. The difference between generic solutions and solutions that fit your codebase comes down to whether the agent has actually seen your patterns.",
        "timing": "2 minutes",
        "discussion": "What happens when you give an agent a vague prompt like 'Add rate limiting'? What would a more grounded version look like?",
        "context": "This is the transition from Lesson 5's grounding concepts to tactical execution. Students should start thinking of grounding as active, not passive.",
        "transition": "Let's look at the first technique: showing agents actual code instead of abstract documentation."
      }
    },
    {
      "type": "code",
      "title": "Ground in Code: Concrete Over Abstract",
      "language": "text",
      "code": "INEFFECTIVE:\n'Add rate limiting middleware to the API'\n\nEFFECTIVE:\nSearch for existing middleware patterns,\nespecially authentication. Check our\nRedis configuration. Then propose rate\nlimiting that follows the same error\nhandling, export structure, and Redis\nclient usage you found.",
      "caption": "Abstract prompts trigger pattern completion; grounded prompts trigger codebase discovery",
      "speakerNotes": {
        "talkingPoints": "When you say 'add rate limiting,' the agent generates a plausible solution from training data—probably something it's seen in 10,000 code repositories. When you say 'follow the patterns you find in our codebase,' the agent is forced to search, read, analyze, and synthesize. The first produces generic code. The second produces code that fits your architecture.",
        "timing": "3 minutes",
        "discussion": "Walk through what the agent does with the effective prompt: search for middleware, read auth implementation, check Redis config, analyze patterns, propose something that matches.",
        "context": "Real-world: One team had an agent generate a database utility that used a different connection pattern than their existing code. The bug was subtle—it worked, but violated their conventions. They lost 3 hours debugging because the implementation looked right but didn't match their patterns.",
        "transition": "Now let's talk about a specific technique: using questions to load context into the window."
      }
    },
    {
      "type": "concept",
      "title": "Questions Load Context, They Don't Test Knowledge",
      "content": [
        "Asking 'How does X work?' triggers search→read→synthesis",
        "That synthesis now lives in context window for next steps",
        "Questions are read-only—safe for autonomous execution",
        "Pre-loads working memory before implementation tasks"
      ],
      "speakerNotes": {
        "talkingPoints": "This is a mental model shift. You're not asking the agent to demonstrate knowledge—you're triggering a sequence that populates the context window. When you ask 'How does our authentication middleware work?', the agent searches, reads files, analyzes patterns, and synthesizes findings. All that information is now in the context. The next prompt—'Now add rate limiting'—doesn't need to search again. It's already loaded.",
        "timing": "2 minutes",
        "discussion": "What's the difference between asking a question to test knowledge vs. asking it to prime the context window? Why is this important for agent execution?",
        "context": "Production practice: Expert teams use questions as deliberate context engineering. Instead of writing one massive prompt, they ask 2-3 exploratory questions first, then execute implementation. This is faster and more reliable.",
        "transition": "The next technique is more aggressive: forcing evidence to prevent hallucination."
      }
    },
    {
      "type": "codeComparison",
      "title": "Require Evidence: Force Grounding Over Guessing",
      "leftCode": {
        "label": "Without Evidence Requirement",
        "language": "text",
        "code": "What's causing the auth error\nwhen users log in?"
      },
      "rightCode": {
        "label": "With Evidence Requirement",
        "language": "text",
        "code": "What's causing the auth error?\nProvide evidence: file paths,\nline numbers, actual values from\nconfig/logs, and stack traces."
      },
      "speakerNotes": {
        "talkingPoints": "Without evidence requirement, the agent uses pattern completion. It gives you a plausible answer based on what's common in training data: 'Probably a database timeout or null pointer.' With evidence requirement, the agent must read your actual code, trace execution, and cite specifics. This converts hallucination into grounding.",
        "timing": "3 minutes",
        "discussion": "When the agent provides evidence, what does that tell you about its analysis? Why is specificity (file:line, not 'the auth file') critical?",
        "context": "Real example from the material: OAuth users have null profile objects. Without evidence requirement, agent guesses. With it, agent reads oauth.ts:134 and cites the exact skipped step.",
        "transition": "Evidence works best combined with Chain-of-Thought for complex debugging. Let's see that together."
      }
    },
    {
      "type": "code",
      "title": "Evidence + Chain-of-Thought: Execution Control",
      "language": "text",
      "code": "Debug the null pointer at\nusers/:id/profile endpoint.\n\n1. Read the endpoint handler\n2. Trace how profile is loaded\n3. Check OAuth creation logic\n4. Find where profile is null\n\nFor each step, provide:\n- File path and line numbers\n- Exact code or config values\n- Your reasoning",
      "caption": "CoT controls execution path; evidence ensures each step is grounded in actual code",
      "speakerNotes": {
        "talkingPoints": "This combines two techniques: Chain-of-Thought gives the agent an execution roadmap, evidence forces grounding at every step. The agent can't take shortcuts or guess—it must find the actual code and cite it. This is the gold standard for complex debugging with agents.",
        "timing": "2 minutes",
        "discussion": "Why does combining these two techniques work better than either alone?",
        "context": "Complex debugging requires both structure (CoT) and verification (evidence). Without structure, the agent meanders. Without evidence, it guesses.",
        "transition": "We've covered three grounding techniques. The final one is your judgment: use your mental model to catch logic errors."
      }
    },
    {
      "type": "concept",
      "title": "Challenge Logic With Your Engineering Judgment",
      "content": [
        "LLMs complete patterns statistically, not logically",
        "Your mental model catches inconsistencies agents miss",
        "When something doesn't fit: 'If X is true, how can Y happen?'",
        "Challenge forces agent to re-examine and ground in reality"
      ],
      "speakerNotes": {
        "talkingPoints": "This is where your expertise matters most. Agents are pattern completion machines. If the patterns in training data suggest that port 3000 is common, the agent will confidently say 'uses port 3000' even if your logs show 8080. Your job is to notice when the logic doesn't hold and force re-examination with evidence.",
        "timing": "2 minutes",
        "discussion": "Share an example where an agent's answer sounded plausible but was wrong. What was your mental model telling you?",
        "context": "This is why senior engineers work well with agents—you already have strong mental models of how systems should behave. Use that to validate agent reasoning.",
        "transition": "Now that we've covered grounding techniques, let's talk about the next phase: reviewing the agent's plan before execution."
      }
    },
    {
      "type": "concept",
      "title": "Plan Review: Before Autonomous Execution",
      "content": [
        "Review strategy and reasoning, not just proposed changes",
        "Was grounding thorough? Any missed considerations?",
        "Pattern adherence—does this fit our codebase?",
        "Scope check—is the agent trying to do too much?"
      ],
      "speakerNotes": {
        "talkingPoints": "Before letting the agent execute code changes, you need to validate the plan. This isn't line-by-line code review—it's architectural fit. You're checking: Did the agent actually understand the problem? Did it consider all constraints? Does its approach match our patterns? If the answer is 'I'm not sure,' that's a grounding failure—stop and add context before execution.",
        "timing": "3 minutes",
        "discussion": "What questions do you ask when reviewing an agent's plan? What red flags indicate shallow grounding?",
        "context": "Catching grounding failures at the planning stage saves hours of debugging later. A bad plan caught before execution is a quick correction. A bad implementation found after autonomous execution requires rewriting.",
        "transition": "There's one specific pattern to watch for: agents inventing instead of reusing."
      }
    },
    {
      "type": "concept",
      "title": "Watch For: Invention Over Reuse",
      "content": [
        "Agents default to generating plausible code from training",
        "8x more duplicated code blocks in AI-generated code",
        "Red flags: 'Create new utility,' 'Implement helper'",
        "Intervention: Force discovery before implementation"
      ],
      "speakerNotes": {
        "talkingPoints": "This is the DRY principle enforced against agent defaults. Agents don't naturally discover and reuse existing code because invention is statistically easier—they're pattern completing from millions of examples. GitClear's analysis shows AI code has 8x more duplication. When you see 'Create a new utility for X,' your response should be: 'Search for existing utilities first. If they don't exist, then create new.' This forces discovery over invention.",
        "timing": "2 minutes",
        "discussion": "Why is invention statistically easier for agents than discovery? What's the difference in effort for the agent between these two approaches?",
        "context": "Real team scenario: Agent proposed a new error handling utility. They already had one. Without intervention, they would have added duplication. With it, they discovered the existing utility and used it.",
        "transition": "Now let's talk about safety nets: checkpointing before execution."
      }
    },
    {
      "type": "concept",
      "title": "Checkpointing: Your Safety Net",
      "content": [
        "Agents make mistakes frequently—checkpointing is essential",
        "Create restore point → execute → validate → keep or revert",
        "Claude Code: Press ESC twice to checkpoint",
        "Without checkpointing: commit far more frequently"
      ],
      "speakerNotes": {
        "talkingPoints": "Agents are probabilistic. They get things wrong. The good news: as your prompting improves, mistakes decrease. The essential skill is reversing mistakes quickly. Modern tools like Claude Code have built-in checkpointing—use them. If your tool lacks it, treat version control as your checkpoint mechanism and commit after every successful increment.",
        "timing": "2 minutes",
        "discussion": "How does checkpointing change your risk tolerance with agents? What does 'successful increment' mean?",
        "context": "Checkpointing lets you experiment aggressively without gambling on irreversible changes. It's the difference between a frustrating session and a productive one.",
        "transition": "Once planning is solid and checkpoints are set, you can move to autonomous execution. For complex work, that means parallelization."
      }
    },
    {
      "type": "code",
      "title": "Git Worktrees: Enable True Parallelization",
      "language": "bash",
      "code": "git worktree add ../feature-a feat/auth\ngit worktree add ../feature-b feat/rate-limit\ngit worktree list",
      "caption": "Multiple branches checked out simultaneously with isolated working directories",
      "speakerNotes": {
        "talkingPoints": "Git worktrees solve a critical problem: how to run multiple agents on different tasks without conflicts. Each worktree is a separate directory with a different branch. You can run Agent A on feature-a while Agent B works on feature-b, with zero interference. This accelerates development dramatically for complex features.",
        "timing": "2 minutes",
        "discussion": "How does this compare to traditional branch switching? What does true parallelization enable?",
        "context": "Production practice: Teams working with agents on parallel features use worktrees exclusively. Without them, you're forced into sequential work.",
        "transition": "Parallelization requires infrastructure. Let's talk about terminal customization and modern CLI tools."
      }
    },
    {
      "type": "concept",
      "title": "Terminal Infrastructure for Multi-Agent Workflows",
      "content": [
        "Terminal becomes mission-critical with parallel agents",
        "GPU-accelerated terminals: Ghostty, Kitty, WezTerm, Alacritty",
        "Modern CLI tools: fzf, lazygit, eza, micro",
        "Use best tool for each task—pragmatism over ideology"
      ],
      "speakerNotes": {
        "talkingPoints": "When you're running 3 agents in parallel, your terminal is no longer just a command prompt—it's infrastructure. You need session management, rapid context switching, visual indicators for different agent contexts. Modern terminals offer IDE-level features. Invest in customization. For CLI tools, each solves a specific friction point: fzf finds files across worktrees, lazygit manages branches visually, eza makes directory scanning faster.",
        "timing": "3 minutes",
        "discussion": "What terminal are you using? What customizations would help with parallel agent workflows? Have you tried any of these modern CLI tools?",
        "context": "Terminal investment pays off across every development session, not just agent work. This is foundational infrastructure.",
        "transition": "But don't be dogmatic—use CLI and UI tools pragmatically."
      }
    },
    {
      "type": "comparison",
      "title": "CLI vs UI Tools: Pragmatic Tool Selection",
      "left": {
        "label": "Terminal-Only Dogmatism",
        "content": [
          "Everything via keyboard",
          "Slower for symbol search",
          "Hard to view large files",
          "Reduced navigation efficiency"
        ]
      },
      "right": {
        "label": "Pragmatic Mixed Approach",
        "content": [
          "IDE for navigation and exploration",
          "CLI for quick edits and git ops",
          "Terminal for parallel session management",
          "Best tool for each task"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Don't be religious about tools. IDEs are still the best for symbol search, go-to-definition, call hierarchies, and reading large files. CLI excels at quick edits, git operations across worktrees, and managing multiple sessions. Use each where it's strongest. This is pragmatism, not inconsistency.",
        "timing": "2 minutes",
        "discussion": "What tasks do you do in terminal? What tasks do you do in IDE? Where's the friction? Could the other tool do it better?",
        "context": "This lesson emphasizes pragmatism. Agents are tools, terminals are tools, IDEs are tools. The goal is efficiency, not purity.",
        "transition": "We've covered planning, execution, and infrastructure. Let's wrap up with key takeaways."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways: Planning & Execution",
      "content": [
        "Questions load context into the window for subsequent steps",
        "Require evidence and Chain-of-Thought to force grounding",
        "Review plans for strategy, not just output structure",
        "Watch for invention over reuse during plan review",
        "Checkpoint before execution; commit after validation",
        "Git worktrees enable true parallel agent workflows"
      ],
      "speakerNotes": {
        "talkingPoints": "These six techniques transform how you work with agents. Grounding isn't one-time upfront work—it's continuous. Questions, evidence requirements, and your judgment ensure the agent stays anchored in your actual codebase. Plan review catches failures before execution. Checkpointing makes mistakes reversible. Worktrees enable parallelization. Together, they turn agents from code generators into reliable code-producing machines.",
        "timing": "2 minutes",
        "discussion": "Which of these techniques will you start with? What's the biggest friction point in your current agent workflow?",
        "context": "Lesson 8 covers tests as guardrails—the final validation layer. These planning and execution techniques lay the groundwork for effective testing.",
        "transition": "Next lesson: Tests as Guardrails. We'll cover how automated tests catch agent errors before they reach production."
      }
    }
  ]
}
