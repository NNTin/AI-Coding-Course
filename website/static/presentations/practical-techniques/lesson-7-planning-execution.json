{
  "metadata": {
    "title": "Planning and Execution",
    "lessonId": "lesson-7-planning-execution",
    "estimatedDuration": "35-45 minutes",
    "learningObjectives": [
      "Engineer context through questions",
      "Force grounding with evidence",
      "Review plans before execution",
      "Enable parallel agent workflows"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Planning and Execution",
      "subtitle": "Active Grounding and Parallel Workflows",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "This lesson covers what happens after context gathering—how to actively ground agents during work, review plans before autonomous execution, and set up parallel development workflows. The shift from gathering to using context is critical.",
        "timing": "1 minute",
        "discussion": "Ask: How many of you have had an agent produce code that technically works but doesn't fit your codebase patterns?",
        "context": "Builds on Lesson 5's grounding concepts. Now we apply them tactically during execution.",
        "transition": "Let's start with active context engineering—techniques that keep agents grounded in your actual code."
      }
    },
    {
      "type": "concept",
      "title": "Active Context Engineering",
      "content": [
        "Grounding isn't one-time—it's continuous throughout execution",
        "Load context → Review plan → Execute → Validate → Repeat",
        "When something doesn't fit your mental model, stop and clarify",
        "Turn agents from code generators into reliable production tools"
      ],
      "speakerNotes": {
        "talkingPoints": "Effective execution requires deliberate context management. These techniques keep the agent grounded in your actual codebase, not statistical patterns from training data. It's an ongoing cycle, not a setup step.",
        "timing": "2 minutes",
        "discussion": "What's your current workflow? Do you review agent plans before letting them execute?",
        "context": "Most developers treat context as setup. The shift here is recognizing it as continuous work.",
        "transition": "Let's look at the first technique: always grounding in actual code, not abstractions."
      }
    },
    {
      "type": "codeComparison",
      "title": "Always Ground in Code",
      "leftCode": {
        "label": "Abstract Prompt",
        "language": "text",
        "code": "Add rate limiting middleware."
      },
      "rightCode": {
        "label": "Grounded Prompt",
        "language": "text",
        "code": "Search for existing middleware patterns,\nespecially authentication.\nCheck our Redis configuration.\nThen propose rate limiting that follows\nthe same error handling, export structure,\nand Redis client usage you found."
      },
      "speakerNotes": {
        "talkingPoints": "The abstract prompt leads to generic solutions from training data. The grounded prompt forces the agent to grep for middleware files, read your Redis config, analyze patterns, and match your conventions. Concrete beats abstract every time.",
        "timing": "3 minutes",
        "discussion": "What happens when you give the abstract prompt? The agent generates something that compiles but doesn't fit your codebase.",
        "context": "This is the difference between 'code that works' and 'code that belongs in your codebase.'",
        "transition": "Now let's look at a powerful technique: using questions to load context."
      }
    },
    {
      "type": "codeExecution",
      "title": "Questions Load Context",
      "steps": [
        {
          "line": "Engineer asks: 'How does our auth middleware work?'",
          "highlightType": "human",
          "annotation": "Question triggers context loading, not knowledge testing"
        },
        {
          "line": "Agent searches codebase for auth-related files",
          "highlightType": "execution",
          "annotation": "Search operation populates context"
        },
        {
          "line": "Agent reads middleware implementations",
          "highlightType": "execution",
          "annotation": "File contents now in context window"
        },
        {
          "line": "Agent analyzes patterns and structure",
          "highlightType": "prediction",
          "annotation": "Synthesis creates working knowledge"
        },
        {
          "line": "Synthesis now lives in context window",
          "highlightType": "feedback",
          "annotation": "Context is primed for next request"
        },
        {
          "line": "Engineer follows up: 'Add rate limiting following same pattern'",
          "highlightType": "human",
          "annotation": "Second request leverages loaded context"
        },
        {
          "line": "Agent implements using already-loaded patterns",
          "highlightType": "prediction",
          "annotation": "No new search needed—knowledge already present"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "When you ask 'How does X work?', you're not testing knowledge—you're triggering a sequence that loads context. The synthesis lives in the window. Follow-up requests use that primed context. Questions are a context engineering tool.",
        "timing": "3-4 minutes",
        "discussion": "Why is this more reliable than packing everything into one massive prompt?",
        "context": "Questions are safe to execute autonomously—read-only operations with minimal risk. If the explanation is wrong, ignore and refine.",
        "transition": "But what if the agent still makes things up? Let's force grounding with evidence requirements."
      }
    },
    {
      "type": "codeComparison",
      "title": "Require Evidence to Force Grounding",
      "leftCode": {
        "label": "Without Evidence",
        "language": "text",
        "code": "Debug the login endpoint -\nit's returning 500 errors"
      },
      "rightCode": {
        "label": "With Evidence Requirement",
        "language": "text",
        "code": "Debug the login endpoint -\nit's returning 500 errors.\n\nExplain the root cause with evidence:\nfile paths, line numbers,\nactual error messages."
      },
      "speakerNotes": {
        "talkingPoints": "Without evidence requirement, agent might respond 'Probably a database timeout or null pointer exception'—pattern completion from training data. With evidence requirement, agent MUST read the code to provide file paths and line numbers. Cannot provide evidence without retrieving it.",
        "timing": "3 minutes",
        "discussion": "What constitutes good evidence? File paths with line numbers, actual config values, specific identifiers, exact error messages.",
        "context": "This converts hallucinated responses into grounded ones. The agent cannot fake evidence without reading your actual code.",
        "transition": "Even with grounding, LLMs make logic errors. Your engineering judgment is still required."
      }
    },
    {
      "type": "concept",
      "title": "Challenge Logic with Your Mental Model",
      "content": [
        "LLMs complete patterns, not sound reasoning",
        "When something doesn't fit, point it out explicitly",
        "Challenge discrepancies: 'If X is true, how can Y happen?'",
        "Force re-examination with evidence from actual files"
      ],
      "speakerNotes": {
        "talkingPoints": "Example: Agent says 'config uses port 3000' but logs show 8080. Challenge it: 'You said port 3000, but logs show 8080. Explain this discrepancy with evidence from config files.' This forces grounded re-examination rather than pattern completion.",
        "timing": "2 minutes",
        "discussion": "Have you caught an agent confidently stating something that contradicted observable facts?",
        "context": "Your engineering skills validate reasoning. Agents handle syntax; you handle logic and correctness.",
        "transition": "Now let's apply these principles during plan review—before the agent executes anything."
      }
    },
    {
      "type": "concept",
      "title": "Detailed Planning: Review Before Execution",
      "content": [
        "How did the agent derive this plan?",
        "Was grounding thorough? (Read files, checked docs, understood constraints?)",
        "Did it miss important considerations? (Security, performance, edge cases?)",
        "Review the 'why' behind the plan, not just the 'what'"
      ],
      "speakerNotes": {
        "talkingPoints": "Before autonomous execution, review the plan's strategy and reasoning. Example: Agent proposes Redis session caching with 24-hour TTL. Did it check existing session implementation? Consider GDPR compliance? Account for cache invalidation on password changes?",
        "timing": "3 minutes",
        "discussion": "What questions do you ask yourself when reviewing an agent's proposed plan?",
        "context": "If grounding was shallow, stop and add context before execution. This is where you catch architectural mismatches.",
        "transition": "Let's look at a specific pattern to watch for: agents inventing instead of reusing."
      }
    },
    {
      "type": "comparison",
      "title": "Watch For: Invention Over Discovery",
      "left": {
        "label": "Red Flags in Plans",
        "content": [
          "'Create a new utility function for...'",
          "'Implement a helper to handle...'",
          "'Build error handling logic...'",
          "'Add validation for...'"
        ]
      },
      "right": {
        "label": "Force Discovery First",
        "content": [
          "Search for existing utilities before creating",
          "Check if helper already exists",
          "Find existing error patterns to follow",
          "Look for existing validation schemas"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "AI-generated code contains 8x more duplicated blocks than human-written code. Agents reinvent because invention is statistically easier than discovery. These phrases signal the agent is generating from training patterns, not discovering your existing code.",
        "timing": "3 minutes",
        "discussion": "What's your strategy when you see these red flags? How do you redirect the agent to discover existing code?",
        "context": "Research confirms this bias—declining code consolidation metrics across the industry. Your job is to enforce DRY principles.",
        "transition": "When execution goes wrong, you need a safety net. Let's talk about checkpointing."
      }
    },
    {
      "type": "concept",
      "title": "Checkpointing: Your Safety Net",
      "content": [
        "Agents make frequent mistakes—especially while learning",
        "Checkpoint rhythm: save → execute → validate → keep or revert",
        "Modern tools have built-in checkpointing (Claude Code: ESC twice)",
        "Without it: commit after each successful increment, before risky ops"
      ],
      "speakerNotes": {
        "talkingPoints": "Agentic coding is probabilistic—you need ability to revert both conversation context and code changes. As your skills improve, rollback needs decrease dramatically. But even experts value checkpointing as a safety net. The difference between frustrating and productive sessions is rollback speed.",
        "timing": "2-3 minutes",
        "discussion": "How often do you currently commit during agent-assisted work? Is it more or less frequent than traditional development?",
        "context": "Checkpointing makes experimentation safe. You can try aggressive approaches knowing you can instantly revert.",
        "transition": "Now let's scale up—running multiple agent instances in parallel."
      }
    },
    {
      "type": "code",
      "title": "Git Worktrees: Parallel Development",
      "language": "bash",
      "code": "# Main repo in ~/project (on main branch)\ngit worktree add ../project-feature-auth feature/auth\ngit worktree add ../project-feature-api feature/api\ngit worktree add ../project-bugfix bugfix/login-error\n\n# Now you have 4 separate directories:\n# ~/project (main)\n# ~/project-feature-auth (feature/auth branch)\n# ~/project-feature-api (feature/api branch)\n# ~/project-bugfix (bugfix/login-error branch)",
      "caption": "Multiple working directories from a single repository enable concurrent agent instances",
      "speakerNotes": {
        "talkingPoints": "Git worktrees allow multiple working directories from a single repo, each with a different branch checked out. This enables running multiple agent instances on different tasks simultaneously without conflicts. Each directory is a full working copy.",
        "timing": "3 minutes",
        "discussion": "Who has used git worktrees before? How might this change your workflow with agents?",
        "context": "For complex features, parallel execution across multiple agent instances dramatically accelerates development.",
        "transition": "Agents can even help set up worktrees. Let's see how to prompt for that."
      }
    },
    {
      "type": "code",
      "title": "Agent-Assisted Worktree Setup",
      "language": "text",
      "code": "Use ArguSeek to research git worktree best practices\nfor parallel development.\n\nCreate 3 worktrees with the following specifications:\n1. Authentication refactor (branch: feat/auth-refactor)\n2. New analytics API (branch: feat/analytics-api)\n3. Dashboard performance improvements (branch: perf/dashboard)\n\nOutput:\n- Exact `git worktree add` commands for each worktree\n- Recommended directory structure following best practices",
      "caption": "Ground with research first, then generate specific commands",
      "speakerNotes": {
        "talkingPoints": "The agent will research worktree workflows, propose a clean directory layout, and generate exact commands for your specific context. This is faster than reading documentation manually. Note the pattern: ground with research first, then generate.",
        "timing": "2 minutes",
        "discussion": "What other setup tasks could benefit from this research-then-generate pattern?",
        "context": "Mix CLI and IDE tools pragmatically—use what's most efficient for each task. Modern terminals like Ghostty or Kitty help manage multiple sessions.",
        "transition": "Let's wrap up with the key takeaways from this lesson."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "Questions load context strategically",
        "Evidence requirements prevent hallucination",
        "Review plans before execution",
        "Checkpoint makes iteration reversible",
        "Worktrees enable parallel agents"
      ],
      "speakerNotes": {
        "talkingPoints": "Questions are context engineering tools, not knowledge tests. Evidence requirements force grounding—agents cannot fake file paths. Your engineering judgment validates logic. Review plan strategy, not just output. Checkpointing makes experimentation safe. Git worktrees enable true parallelization.",
        "timing": "2 minutes",
        "discussion": "Which technique will you try first in your next coding session?",
        "context": "These techniques turn agents from unreliable code generators into reliable tools. The investment in active grounding pays off in reduced iteration cycles.",
        "transition": "Next lesson: Tests as Guardrails—how to validate agent output systematically."
      }
    }
  ]
}
