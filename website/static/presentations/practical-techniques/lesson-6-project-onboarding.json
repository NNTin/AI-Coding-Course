{
  "metadata": {
    "title": "Project Onboarding: Context File Ecosystems",
    "lessonId": "lesson-6-project-onboarding",
    "estimatedDuration": "30-45 minutes",
    "learningObjectives": [
      "Inject project-specific knowledge into AI agents",
      "Choose between AGENTS.md and CLAUDE.md",
      "Implement hierarchical context layering",
      "Bootstrap context files automatically"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "Project Onboarding:\nContext File Ecosystems",
      "subtitle": "Transform agents into project-aware operators",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "Welcome to Lesson 6. This lesson solves a fundamental problem: AI agents arrive at your project with zero institutional knowledge. They see only what's in their context window. No memory. No 'how we do things here.' We're going to show you how to codify that knowledge in machine-readable context files so agents become genuinely project-aware.",
        "timing": "1-2 minutes",
        "discussion": "Ask: Has anyone onboarded a new developer? What was the hardest part to communicate?",
        "context": "This bridges Lessons 3-5 (research, planning, grounding) with practical implementation. By end of lesson, students will have a template they can use in their own projects.",
        "transition": "Let's start with the core problem."
      }
    },
    {
      "type": "concept",
      "title": "The Onboarding Problem",
      "content": [
        "New developers face steep learning curve",
        "AI agents have the same problem",
        "Agents see only ~200K tokens (context window)",
        "No memory between conversations",
        "No tribal knowledge from Slack/culture"
      ],
      "speakerNotes": {
        "talkingPoints": "When you join a new project, the first week is brutal. Unfamiliar architecture, tech stack decisions, tribal knowledge in Slack threads, undocumented bash scripts. AI agents face an identical problem—except they can't grab coffee with a senior engineer to fill gaps. The solution: codify your project context in hierarchical, machine-readable files. This is 'project memory' for agents.",
        "timing": "2-3 minutes",
        "discussion": "Ask: What's the biggest knowledge gap when onboarding? What takes longest to internalize? Discuss the parallel between human and AI onboarding.",
        "context": "In production, teams often spend 2-3 weeks getting new developers productive. Well-structured context files can compress that to days for AI agents, and hours for humans who can read them.",
        "transition": "The solution is context files. Let's explore the two main approaches."
      }
    },
    {
      "type": "concept",
      "title": "Context File Ecosystem",
      "content": [
        "Inject project knowledge between system prompt and input",
        "Two industry standards: AGENTS.md and CLAUDE.md",
        "AGENTS.md: vendor-neutral, single file at root",
        "CLAUDE.md: Claude Code only, hierarchical merging",
        "Both give agents 'project memory' without context bloat"
      ],
      "speakerNotes": {
        "talkingPoints": "Context files are markdown documents that live in your repo and get injected into the LLM's context at runtime. They act as 'project memory.' The industry has converged on two approaches: AGENTS.md (works with GitHub Copilot, Cursor, Windsurf—the universal standard) and CLAUDE.md (Claude Code specific, but with hierarchical power). The key insight: you're not duplicating documentation. Your README should contain 90% of what AI needs. Context files add only AI-specific operational details.",
        "timing": "3-4 minutes",
        "discussion": "Ask: Which tools does your team use? Does everyone use the same AI assistant, or mixed tools? This determines which approach fits your workflow.",
        "context": "Production teams often use mixed-tool environments. One engineer uses Cursor, another uses Copilot, another uses Claude Code. Context file strategy must account for this heterogeneity.",
        "transition": "Let's compare these two approaches side by side."
      }
    },
    {
      "type": "comparison",
      "title": "AGENTS.md vs CLAUDE.md",
      "left": {
        "label": "AGENTS.md (Vendor-Neutral)",
        "content": [
          "Single file at repository root",
          "Loaded by Copilot, Cursor, Windsurf",
          "No hierarchical merging",
          "Best for homogeneous tool environments",
          "Not supported in Claude Code"
        ]
      },
      "right": {
        "label": "CLAUDE.md (Hierarchical)",
        "content": [
          "Multiple files at different levels",
          "Claude Code automatically merges all applicable files",
          "Global → project → module hierarchy",
          "Best for complex, large codebases",
          "Claude Code only"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "AGENTS.md is the universal standard: one file, works everywhere except Claude Code. Good for teams using mixed tools. CLAUDE.md is Claude Code-specific but offers something AGENTS.md can't: hierarchical loading. You can define universal preferences in ~/.claude/CLAUDE.md, project standards at the root, and module-specific rules in subdirectories. More specific files override general ones, but non-conflicting rules from all levels remain active.",
        "timing": "3 minutes",
        "discussion": "Ask: Does your team use one AI tool or multiple? This determines which standard you should lead with.",
        "context": "Example: A team uses Claude Code for backend work but Copilot in their IDEs. They'd use AGENTS.md for shared knowledge (what everyone sees) and CLAUDE.md for Claude-specific power features (advanced context engineering).",
        "transition": "If you're using Claude Code, the hierarchical approach unlocks powerful patterns. Let's visualize how it works."
      }
    },
    {
      "type": "visual",
      "component": "AbstractShapesVisualization",
      "caption": "Hierarchical context merges files from multiple levels automatically.",
      "speakerNotes": {
        "talkingPoints": "This visualization shows the hierarchical loading system in Claude Code. Your global ~/.claude/CLAUDE.md applies everywhere. Project-level /CLAUDE.md applies to all work in that repo. Subdirectory CLAUDE.md files apply to work in that module. More specific files override general ones. The system is additive: non-conflicting rules from all levels remain active. You're not replacing context; you're layering it.",
        "timing": "2 minutes",
        "discussion": "Ask: If you had global preferences about code style, project-specific rules about architecture, and module-specific rules about testing, how would you layer them? Walk through an example.",
        "context": "Production example: Global CLAUDE.md defines minimalism, no temporary files, always verify code works. Project CLAUDE.md defines React conventions, TypeScript patterns. src/components/CLAUDE.md adds JSDoc requirements for exported components. All three apply when you work in src/components/.",
        "transition": "Now let's look at actual examples. Here's what global context looks like."
      }
    },
    {
      "type": "code",
      "title": "Global Context Example",
      "language": "markdown",
      "code": "# Mindset\nYou are a senior architect\nwith 20 years of experience.\n\n# Search Protocol\nUse ChunkHound to research\narchitecture and style.\nPREFER CODE RESEARCH OVER\nSUB AGENTS.\n\n# Coding Standards\nKISS - Keep It Simple.\nOptimize for readability.\nRun tests after major\nchanges. Fix bugs by\ndeleting code when possible.",
      "caption": "Personal preferences applied across all projects",
      "speakerNotes": {
        "talkingPoints": "This is the course author's actual ~/.claude/CLAUDE.md. It's intentionally short: mindset, search protocol, coding standards, operational rules. These are universal preferences that should apply everywhere. Global context is where you codify 'how I work,' not project-specific details. Keep it minimal and opinionated. This becomes a personal operating system for how you use AI.",
        "timing": "2-3 minutes",
        "discussion": "Ask: What would go in YOUR global context? What principles do you apply across all projects? Start drafting mentally.",
        "context": "In production, senior engineers often have deeply tuned global context that reflects years of hard-won lessons. Sharing this with team members (if they use the same tool) accelerates their growth dramatically.",
        "transition": "Global context is universal. Project context is specific to one codebase. Here's what that looks like."
      }
    },
    {
      "type": "code",
      "title": "Project Context Example",
      "language": "markdown",
      "code": "# AI Coding Course\n\n## Technology Stack\nDocusaurus 3.9.2, TypeScript\n5.6.2, React 19.0\n\n## Development Commands\ncd website && npm start\nnpm run build\nnpm run deploy\n\n## Tone & Style\nCoworker-level communication.\nAssume strong fundamentals.\nFocus on practical application.\nProduction-ready examples.",
      "caption": "Tech stack and conventions specific to one project",
      "speakerNotes": {
        "talkingPoints": "This is from the actual AI Coding Course repository. Project context captures what a new team member needs to be productive in the first hour: tech stack details, common commands, communication tone, architectural philosophy. Notice what's NOT here: basic JavaScript tutorials, beginner explanations. Those go in README. Context files are operational shortcuts for people who already understand the domain.",
        "timing": "2 minutes",
        "discussion": "Ask: What would go in your project's context file? What assumptions can you make about developers joining your team?",
        "context": "Production teams often generate these semi-automatically by extracting README, package.json, and key architectural docs, then adding AI-specific operational details (MCP servers, non-standard test commands, warnings about undocumented dependencies).",
        "transition": "Now here's the meta-move: instead of manually writing these files, let agents generate them. This applies Lessons 3-5 to the context file problem itself."
      }
    },
    {
      "type": "codeExecution",
      "title": "Automated Context Generation Workflow",
      "steps": [
        {
          "line": "Engineer specifies: 'Generate CLAUDE.md for this\nrepository using grounding'",
          "highlightType": "human",
          "annotation": "Task specification with method (Lesson 3-5)"
        },
        {
          "line": "Agent executes: ChunkHound.code_research()\nfor architecture and patterns",
          "highlightType": "execution",
          "annotation": "Automated codebase analysis (Lesson 5)"
        },
        {
          "line": "Agent receives: Code patterns, module\nresponsibilities, testing conventions",
          "highlightType": "feedback",
          "annotation": "Codebase context injected"
        },
        {
          "line": "Agent executes: ArguSeek.research_iteratively()\nfor framework docs and best practices",
          "highlightType": "execution",
          "annotation": "Domain knowledge retrieval"
        },
        {
          "line": "Agent receives: Framework documentation,\nsecurity guidelines, ecosystem context",
          "highlightType": "feedback",
          "annotation": "External knowledge grounded in project"
        },
        {
          "line": "Agent predicts: Synthesizes codebase and\ndomain insights into structured plan",
          "highlightType": "prediction",
          "annotation": "Chain-of-Thought (Lesson 4)"
        },
        {
          "line": "Agent executes: Generates context file\nusing prompt optimization techniques",
          "highlightType": "execution",
          "annotation": "Production context file created"
        },
        {
          "line": "Engineer validates: Tests context with\ntypical task, iterates on gaps",
          "highlightType": "human",
          "annotation": "Human validation completes loop"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "This is the meta-application of Lessons 3-5. Instead of manually drafting context files over weeks, use the four-phase workflow to have agents bootstrap their own context. Research phase: Use ChunkHound to understand architecture, patterns, conventions. Use ArguSeek to fetch framework documentation and best practices. Plan phase: Agent synthesizes insights into a structured context file plan. Execute phase: Generate the context file using prompt optimization. Validate phase: Test with a real task and iterate. The result: production-ready context in one iteration.",
        "timing": "4-5 minutes",
        "discussion": "Walk through each step. Ask: Which part requires human judgment? (Answer: validation—tribal knowledge, security considerations, non-obvious gotchas only humans know.) Which parts can be fully automated? (Answer: research, synthesis, initial generation.)",
        "context": "Production example: A team spends 2-3 weeks manually crafting context files. Using this workflow, they generate a candidate in 1 hour, validate and refine in another 1-2 hours, and have production context deployed.",
        "transition": "Let's see the actual prompt that drives this workflow."
      }
    },
    {
      "type": "code",
      "title": "Bootstrap Prompt Example",
      "language": "text",
      "code": "Generate a production-ready CLAUDE.md\nfor this repository.\n\nResearch phase:\n- Use ChunkHound.code_research() to\n  find architecture, patterns, style\n- Use ArguSeek.research_iteratively()\n  to fetch framework docs\n\nPlan phase: Synthesize insights\ninto structured context plan\n\nExecute phase: Generate CLAUDE.md\nusing grounding from both phases\n\nValidate phase: Test with a\ntypical task, iterate on gaps",
      "caption": "Demonstrates grounding + Chain-of-Thought for meta-task",
      "speakerNotes": {
        "talkingPoints": "This prompt demonstrates everything from Lessons 3-5 applied to the context file problem itself. Notice the structure: it specifies exact tools (ChunkHound, ArguSeek), the workflow phases, and validation criteria. It's grounded (uses actual codebase + domain research), has explicit Chain-of-Thought structure (plan, execute, validate), and expects a specific output format. The prompt is self-documenting: someone reading it understands the entire process without additional explanation.",
        "timing": "2-3 minutes",
        "discussion": "Ask: How would you modify this prompt for your own codebase? What additional constraints would you add? (Security concerns? Non-standard tooling? Tribal knowledge?)",
        "context": "In production, teams often add a final step: 'After generation, manually add 5-10 items about non-obvious gotchas, security considerations, and incident post-mortems that only humans know.'",
        "transition": "Let's wrap up with the key takeaways."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "Context files codify project memory without context bloat",
        "Use AGENTS.md for mixed-tool teams; CLAUDE.md for Claude Code power",
        "Layer hierarchically: global → project → module specificity",
        "Bootstrap context files automatically using grounding + research",
        "Add tribal knowledge manually; automation handles structural work"
      ],
      "speakerNotes": {
        "talkingPoints": "Context files transform agents from generic code generators into project-aware operators. You're not writing documentation twice; you're extracting operational knowledge and making it machine-readable. Use the vendor-neutral standard (AGENTS.md) if your team uses multiple tools. Use hierarchical context (CLAUDE.md) if you're committed to Claude Code—it's worth it for large codebases. Most importantly: start automated, then iterate. Let agents bootstrap context files; humans validate and add what machines can't discover.",
        "timing": "2-3 minutes",
        "discussion": "Action items: 1) Audit your current project documentation. What should go in context files? 2) Draft a global context file reflecting your personal coding philosophy. 3) Generate a project context file using the bootstrap workflow. 4) Share context files with team members—they'll accelerate their own understanding.",
        "context": "Production teams that implement this pattern report 40-60% reduction in context switching time for new developers and 3-5x improvement in AI agent accuracy on project-specific tasks.",
        "transition": "Next lesson: Lesson 7 covers planning and execution at scale. We'll show how to structure complex projects so agents can reason about multiple components simultaneously."
      }
    }
  ]
}
