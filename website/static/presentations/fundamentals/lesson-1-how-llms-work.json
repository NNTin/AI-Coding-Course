{
  "metadata": {
    "title": "How LLMs Work",
    "lessonId": "lesson-1-how-llms-work",
    "estimatedDuration": "30-40 minutes",
    "learningObjectives": [
      "Distinguish LLM from agent",
      "Understand token prediction mechanics",
      "Avoid anthropomorphizing AI tools",
      "Apply operator mindset"
    ]
  },
  "slides": [
    {
      "type": "title",
      "title": "How LLMs Work",
      "subtitle": "Understanding the machinery before operating it",
      "content": [],
      "speakerNotes": {
        "talkingPoints": "Welcome to the first lesson. Before we can effectively use AI agents, we need to understand what they actually are. The terminology makes them sound magical - they're not. We're going to demystify LLMs and establish a foundation for everything that follows.",
        "timing": "1-2 minutes",
        "discussion": "Ask: How many of you have used ChatGPT or Copilot? How would you describe what's happening under the hood?",
        "context": "This lesson sets the mental model for the entire course. Getting this right prevents the common mistakes we'll discuss.",
        "transition": "Let's start with a paradigm shift that's reshaping our profession."
      }
    },
    {
      "type": "comparison",
      "title": "The Manufacturing Paradigm Shift",
      "left": {
        "label": "Before CNC",
        "content": [
          "Operators manually shaped every part",
          "Craftsmanship-dependent quality",
          "Limited by human speed and precision",
          "Hard to replicate exact specifications"
        ]
      },
      "right": {
        "label": "After CNC",
        "content": [
          "Operators design and program machines",
          "Consistent, repeatable output",
          "Massive gains in throughput",
          "Focus shifts to verification"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Manufacturing went through this exact transformation. Lathe operators didn't become obsolete - their role evolved. They stopped manually shaping parts and started designing specifications, programming machines, and verifying output. Same transformation is happening in software.",
        "timing": "2-3 minutes",
        "discussion": "Ask: What do you think manufacturing operators had to learn when CNC machines arrived? How might that parallel our situation?",
        "context": "This analogy helps senior engineers see they're not being replaced, but their role is evolving. The skills change, but domain expertise becomes MORE important.",
        "transition": "Software engineering is undergoing the same shift. Let's see what that looks like."
      }
    },
    {
      "type": "comparison",
      "title": "Software Engineering Transformation",
      "left": {
        "label": "Traditional",
        "content": [
          "Engineers write code line-by-line",
          "Focus on syntax and implementation",
          "Manual execution of repetitive tasks",
          "Bandwidth limited by typing speed"
        ]
      },
      "right": {
        "label": "Agent-Driven",
        "content": [
          "Engineers orchestrate AI agents",
          "Focus on architecture and verification",
          "Automated execution of routine work",
          "Bandwidth limited by oversight capacity"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "The shift isn't about losing control - it's about gaining bandwidth. You're not writing less code, you're directing more code production. Your domain expertise becomes the bottleneck, not your typing speed.",
        "timing": "2 minutes",
        "discussion": "What tasks in your current work feel most repetitive? Those are prime candidates for agent automation.",
        "context": "Senior engineers often fear this shift means junior work disappears. Reality: it means senior oversight scales across more output.",
        "transition": "But before we can operate these tools effectively, we need to understand what they actually are. Let's look at first principles."
      }
    },
    {
      "type": "concept",
      "title": "LLM = Brains (Token Prediction Engine)",
      "content": [
        "Predicts the next most probable token in a sequence",
        "Processes ~200K tokens of context (working memory)",
        "Samples from probability distributions learned from training",
        "Has zero consciousness, intent, or feelings"
      ],
      "speakerNotes": {
        "talkingPoints": "An LLM is fundamentally a statistical pattern matcher. It's read most of the internet and learned to generate convincing continuations of text patterns. Think of it as incredibly sophisticated autocomplete - nothing more.",
        "timing": "3 minutes",
        "discussion": "When you use autocomplete in your IDE, do you think it 'understands' your code? Why do we assume LLMs are different?",
        "context": "This framing is deliberately reductive because it's accurate. The power comes from scale and training data, not from any form of understanding.",
        "transition": "Let's clarify what a token actually is, since that's the fundamental unit we're working with."
      }
    },
    {
      "type": "concept",
      "title": "What's a Token?",
      "content": [
        "Atomic unit of LLM - the 'pixel' of text processing",
        "Averages ~3-4 characters (varies by word frequency)",
        "Cost: Providers bill per token (input + output)",
        "Context: ~200K token window is your memory budget",
        "Rule of thumb: 1 token ≈ 0.75 words in English"
      ],
      "speakerNotes": {
        "talkingPoints": "Tokens matter for three reasons: cost, context limits, and performance. Common words like 'the' are single tokens. Longer or rare words get split into subwords. A typical source file runs 3K-15K tokens. This paragraph would be about 150 tokens.",
        "timing": "2 minutes",
        "discussion": "How might token limits affect how you structure prompts for a large codebase?",
        "context": "Understanding tokens helps engineers optimize both cost and performance. Token-efficient prompts mean faster responses and lower bills.",
        "transition": "Now let's demystify the marketing language we use when talking about LLMs."
      }
    },
    {
      "type": "marketingReality",
      "title": "Marketing vs Reality",
      "metaphor": {
        "label": "We Say (Metaphor)",
        "content": [
          "The agent thinks",
          "The agent understands",
          "The agent learns",
          "The agent reasons"
        ]
      },
      "reality": {
        "label": "What's Actually Happening",
        "content": [
          "Token predictions through attention layers",
          "Pattern matching against training data",
          "Weights updated during training only",
          "Sequential predictions building on each other"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Every time we use human verbs for LLMs, we're speaking metaphorically. 'Thinks' means generating tokens through transformer layers. 'Understands' means pattern matching. 'Learns' only happens during training - not during your conversation. 'Reasons' is just sequential predictions.",
        "timing": "3 minutes",
        "discussion": "Why do you think we use these metaphors? What are the dangers of taking them literally?",
        "context": "This table should be a reference point. When you catch yourself anthropomorphizing, come back to the right column.",
        "transition": "The LLM is just the brains. It can only generate text. Let's look at what gives it a body."
      }
    },
    {
      "type": "concept",
      "title": "Agent Software = Body (Execution Layer)",
      "content": [
        "File operations: Read, Write, Edit",
        "Command execution: Bash, git, npm, pytest",
        "Code search: Grep, Glob",
        "API calls: Fetch docs, external resources"
      ],
      "speakerNotes": {
        "talkingPoints": "The LLM alone can only generate text. The agent framework wraps it with tools that enable action in the real world. This is plain old deterministic software - nothing magical about it. The LLM predicts which tool to use, the agent executes it.",
        "timing": "2 minutes",
        "discussion": "What tools would you want an agent to have access to in your codebase? What tools would you restrict?",
        "context": "The LLM is the brains. The agent framework is the body. Both are required for useful work.",
        "transition": "Let's trace through exactly what happens when an agent 'implements a feature'."
      }
    },
    {
      "type": "codeExecution",
      "title": "What Actually Happens When an Agent Works",
      "steps": [
        {
          "line": "LLM predicts: 'I should read the existing auth middleware'",
          "highlightType": "prediction",
          "annotation": "Token prediction drives next action"
        },
        {
          "line": "Agent executes: Read(src/auth.ts)",
          "highlightType": "execution",
          "annotation": "Deterministic tool execution"
        },
        {
          "line": "File content returned to context",
          "highlightType": "feedback",
          "annotation": "Operation result available to LLM"
        },
        {
          "line": "LLM predicts code changes based on patterns seen",
          "highlightType": "prediction",
          "annotation": "Pattern matching against training data"
        },
        {
          "line": "Agent executes: Edit(file, old, new)",
          "highlightType": "execution",
          "annotation": "Code modification"
        },
        {
          "line": "LLM predicts: 'run tests'",
          "highlightType": "prediction",
          "annotation": "Next step prediction"
        },
        {
          "line": "Agent executes: Bash('npm test')",
          "highlightType": "execution",
          "annotation": "Test execution"
        },
        {
          "line": "LLM analyzes output → predicts fixes → loop continues",
          "highlightType": "summary",
          "annotation": "Iteration until task complete"
        }
      ],
      "speakerNotes": {
        "talkingPoints": "No magic here. No consciousness. Just probability distributions driving tool execution. The LLM predicts what to do, the agent executes it, results feed back into context, repeat. This loop is the core of every agent interaction.",
        "timing": "3-4 minutes",
        "discussion": "At which step could things go wrong? How would you detect and correct errors in this loop?",
        "context": "Understanding this loop is crucial for debugging agent behavior. When something fails, trace back through these steps.",
        "transition": "Now let's discuss why this mechanical understanding matters for you as an operator."
      }
    },
    {
      "type": "concept",
      "title": "Three Critical Operator Errors",
      "content": [
        "Error 1: Assuming the agent 'knows' things",
        "Error 2: Expecting the agent to 'care' about outcomes",
        "Error 3: Treating it like a teammate instead of a tool"
      ],
      "speakerNotes": {
        "talkingPoints": "These three errors stem from anthropomorphizing. The agent only sees current context - about 200K tokens. It has no preferences or goals. It executes your literal instructions. Treating it like a colleague leads to frustration and poor results.",
        "timing": "2 minutes",
        "discussion": "Have you made any of these errors? What happened?",
        "context": "We'll cover fixes for each of these in Lesson 3 with the three operator principles.",
        "transition": "Let's look at each error and its fix."
      }
    },
    {
      "type": "comparison",
      "title": "Errors and Their Fixes",
      "left": {
        "label": "Error",
        "content": [
          "Assuming agent 'knows' things",
          "Expecting agent to 'care'",
          "Treating it as a teammate"
        ]
      },
      "right": {
        "label": "Fix",
        "content": [
          "Provide explicit context (~200K tokens)",
          "Be precise, include constraints",
          "Maintain tool mindset"
        ]
      },
      "speakerNotes": {
        "talkingPoints": "Each error has a direct fix. Don't assume knowledge - provide it. Don't expect care - specify constraints. Don't collaborate - operate. These become the three operator principles we'll explore in depth in Lesson 3.",
        "timing": "2-3 minutes",
        "discussion": "Which of these fixes feels most counterintuitive to you? Why?",
        "context": "Senior engineers often struggle with the third one most. Years of collaboration habits need to shift.",
        "transition": "Here's an analogy that might help cement this mindset."
      }
    },
    {
      "type": "concept",
      "title": "The CNC Analogy",
      "content": [
        "CNC machine doesn't 'understand' the part it's making",
        "It executes instructions precisely, nothing more",
        "You don't get mad at it for misinterpreting vague coordinates",
        "You provide exact specifications",
        "LLMs are the same - tools that execute language-based instructions"
      ],
      "speakerNotes": {
        "talkingPoints": "A CNC machine has zero comprehension of what it's making. It just follows coordinates. If you give it vague specs, you get garbage output. Same with LLMs - they execute language instructions with impressive fluency but zero comprehension.",
        "timing": "2 minutes",
        "discussion": "If you had to write specifications for a CNC machine, how would your approach differ from giving instructions to a human machinist?",
        "context": "This analogy helps shift from 'managing a junior developer' to 'operating a sophisticated tool'.",
        "transition": "Let's talk about what this 'fancy autocomplete' framing means for your work."
      }
    },
    {
      "type": "concept",
      "title": "The Power of 'Fancy Autocomplete'",
      "content": [
        "Power: Incredibly good at generating seen code patterns",
        "Limitation: No model of correctness, only probability",
        "Implication: You build verification systems (tests, types, lints)",
        "Your role: Architect guardrails, not manage a developer"
      ],
      "speakerNotes": {
        "talkingPoints": "Calling it 'fancy autocomplete' sounds reductive, but it's liberating. These engines are great at generating patterns they've seen before. They have no concept of correctness - only probability. Your job is to create systems that catch probabilistic errors.",
        "timing": "2-3 minutes",
        "discussion": "What verification systems do you already have? How might they need to change for agent-generated code?",
        "context": "Tests, types, and lints become your safety net. They're not optional extras - they're essential for agent workflows.",
        "transition": "Let's wrap up with key takeaways."
      }
    },
    {
      "type": "takeaway",
      "title": "Key Takeaways",
      "content": [
        "LLMs predict tokens, not thoughts",
        "Agent software enables real actions",
        "Operate tools, don't manage teammates",
        "Verification systems catch probabilistic errors"
      ],
      "speakerNotes": {
        "talkingPoints": "Remember: LLMs are token prediction engines wrapped in execution layers. They don't know, care, or understand anything. They're precision instruments that speak English. Your job is to operate them with exact specifications and verification systems.",
        "timing": "2 minutes",
        "discussion": "What's one thing you'll do differently in your next AI interaction based on this lesson?",
        "context": "These principles underpin everything we'll cover in the rest of the course.",
        "transition": "Next lesson, we'll demystify agent architecture and see how your role evolves from engineer to operator."
      }
    }
  ]
}