---
source: intro.md
speakers:
  - name: Alex
    role: Instructor
    voice: Kore
  - name: Sam
    role: Senior Engineer
    voice: Charon
generatedAt: 2025-11-07T13:32:23.650Z
model: claude-haiku-4.5
tokenCount: 1229
---

Alex: So here's where we are in 2025: AI coding assistants work. Companies are shipping features faster. Individual engineers are doing the work of teams. The technology isn't the problem anymore.

Sam: But?

Alex: But almost every engineer who picks up these tools hits the same wall within weeks. They get frustrated and either go back to writing code themselves or use it just for boilerplate. The tool stays superficial.

Sam: What's causing that wall? The tools aren't good enough yet, or is something else going on?

Alex: It's not the tools. It's the mental model. Most developers approach AI agents the way they'd work with a junior developer. You wait for them to understand context. You fix their code line-by-line. You work around context limits like they're personality quirks.

Sam: That sounds exhausting.

Alex: It is. And it misses the whole point of what these tools actually are. AI agents aren't teammates. Think of them differently—they're CNC machines for code. You don't teach a CNC machine design principles. You learn to operate it precisely.

Sam: So the skill isn't in prompt writing, it's in operation?

Alex: Exactly. That's what this course is about. It's operator training for AI coding agents. We're covering the systematic approach used in production environments right now—companies that have actually figured this out.

Sam: What does that look like operationally?

Alex: Three phases: Plan, Execute, Validate. You break work into agent-appropriate tasks. You research the architecture, ground yourself in context. Then you execute with precise prompts, delegate to specialized sub-agents, run operations in parallel. Finally, you validate with tests, review the code critically, and require evidence of correctness.

Sam: Not exactly hand-holding.

Alex: Right. This course assumes you know how to engineer software. You understand design patterns, system design, architecture. We're teaching you how to orchestrate agents that execute autonomously.

Sam: Who actually needs this? It sounds specific.

Alex: You do if you've got three-plus years of professional engineering experience. If you've tried these tools and hit a wall. If you care about production-readiness, not just demos. If you want to move faster without sacrificing code quality.

Sam: What about people who are just starting out?

Alex: Not the right audience. This isn't foundational engineering training. It's advanced operator training for people who already know the fundamentals.

Sam: Fair. So what's actually in the course?

Alex: Three modules. First: Understanding the Tools—mental models and architecture. Second: Methodology—how to prompt effectively, ground work in context, design workflows. Third: Practical Techniques—onboarding to codebases, planning features, testing, reviewing, debugging.

Sam: Sequential order?

Alex: Yeah. Each module builds on the previous concepts. You can't really skip ahead.

Sam: And I assume the exercises are hands-on?

Alex: Mandatory. Reading alone won't build the operating skills you need. You work through exercises on real codebases—your own, not the examples we provide.

Sam: What does "completion" look like? What can you actually do after finishing?

Alex: Onboard to unfamiliar codebases five to ten times faster using agentic research. Refactor complex features reliably with test-driven validation. Debug production issues by delegating analysis to agents. Review code systematically while maintaining critical judgment. Plan and execute features with parallel sub-agent delegation.

Sam: That's a significant productivity shift.

Alex: It is. But the real learning is judgment—knowing when to use agents and when to write code yourself. That's what separates effective operators from frustrated ones.

Sam: Okay, one more thing—I noticed this is a podcast version. Is there something recursive happening here?

Alex: Yeah, actually. The entire course—content, lesson structure, code examples, documentation—was developed using the exact same AI-assisted techniques you're about to learn. We didn't just teach this methodology; we validated it by building the course itself.

Sam: So you're teaching with proof of concept.

Alex: Exactly. Every module was planned, researched, drafted, refined through systematic prompting and agentic research. The podcast version, these scripts—we converted technical content to dialogue using Claude and Gemini. Even the voices are AI-generated.

Sam: That's either clever or slightly ironic.

Alex: Both. It's not marketing. It's validation. If these techniques can produce production-grade training material on their own application, they're robust enough for real work.

Sam: Alright. So where do we actually start?

Alex: Module One: Understanding the Tools. We're going to break down mental models and architecture—what these agents actually are, how they work, what they're good at and bad at.

Sam: Let's go.
